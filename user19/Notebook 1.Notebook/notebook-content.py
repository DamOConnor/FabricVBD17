# Fabric notebook source

# METADATA ********************

# META {
# META   "kernel_info": {
# META     "name": "synapse_pyspark"
# META   },
# META   "dependencies": {
# META     "lakehouse": {
# META       "default_lakehouse": "ded7bbd0-2c15-4c80-94d9-178f9f31e524",
# META       "default_lakehouse_name": "lh_tpch19_100",
# META       "default_lakehouse_workspace_id": "3c6cce90-d67d-4708-9c1f-574ad7d54f9f",
# META       "known_lakehouses": [
# META         {
# META           "id": "ded7bbd0-2c15-4c80-94d9-178f9f31e524"
# META         }
# META       ]
# META     }
# META   }
# META }

# CELL ********************

# Welcome to your new notebook
# Type here in the cell editor to add code!


# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# CELL ********************

df = spark.sql("SELECT * FROM lh_tpch19_100.nation LIMIT 1000")
display(df)

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# CELL ********************


# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# CELL ********************

df = spark.sql("SELECT * FROM lh_tpch19_100.region LIMIT 1000")
display(df)

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# CELL ********************

df = spark.sql("SELECT * FROM lh_tpch19_100.lineitem LIMIT 10")
display(df)

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# CELL ********************

# MAGIC %%sql
# MAGIC select *
# MAGIC from orders
# MAGIC limit 10

# METADATA ********************

# META {
# META   "language": "sparksql",
# META   "language_group": "synapse_pyspark"
# META }

# CELL ********************

# MAGIC %%sql
# MAGIC 
# MAGIC SELECT * FROM lh_tpch19_100.lineitem LIMIT 10

# METADATA ********************

# META {
# META   "language": "sparksql",
# META   "language_group": "synapse_pyspark"
# META }

# CELL ********************

df = spark.sql("SELECT * FROM lh_tpch19_100.orders LIMIT 10")
display(df)

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# CELL ********************

# MAGIC %%sql
# MAGIC 
# MAGIC select count(distinct partkey)
# MAGIC from lineitem

# METADATA ********************

# META {
# META   "language": "sparksql",
# META   "language_group": "synapse_pyspark"
# META }

# CELL ********************

# MAGIC %%sql
# MAGIC describe detail orders

# METADATA ********************

# META {
# META   "language": "sparksql",
# META   "language_group": "synapse_pyspark"
# META }

# MARKDOWN ********************

# Messy Experiments:

# CELL ********************


# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# CELL ********************

# MAGIC %%sql
# MAGIC select t.orderkey as orderkey
# MAGIC from lh_tpch19_100.dbo.lineitem as t

# METADATA ********************

# META {
# META   "language": "sparksql",
# META   "language_group": "synapse_pyspark"
# META }

# CELL ********************

# MAGIC %%sparkr
# MAGIC 
# MAGIC results <- sql("SELECT * FROM lh_tpch19_100.customer LIMIT 1000")
# MAGIC head(results)

# METADATA ********************

# META {
# META   "language": "r",
# META   "language_group": "synapse_pyspark"
# META }

# CELL ********************

# Code generated by Data Wrangler for PySpark DataFrame

from pyspark.sql import functions as F

def clean_data(df):
    # Capitalize the first character in column: 'comment'
    df = df.withColumn('comment', F.initcap(F.col('comment')))
    return df

df_clean = clean_data(df)
display(df_clean)

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# CELL ********************

# MAGIC %%sql
# MAGIC select [$Table].[orderkey] as [orderkey],
# MAGIC     [$Table].[partkey] as [partkey],
# MAGIC     [$Table].[suppkey] as [suppkey],
# MAGIC     [$Table].[linenumber] as [linenumber],
# MAGIC     [$Table].[quantity] as [quantity],
# MAGIC     [$Table].[extendedprice] as [extendedprice],
# MAGIC     [$Table].[discount] as [discount],
# MAGIC     [$Table].[tax] as [tax],
# MAGIC     [$Table].[returnflag] as [returnflag],
# MAGIC     [$Table].[linestatus] as [linestatus],
# MAGIC     [$Table].[shipdate] as [shipdate],
# MAGIC     [$Table].[commitdate] as [commitdate],
# MAGIC     [$Table].[receiptdate] as [receiptdate],
# MAGIC     [$Table].[shipinstruct] as [shipinstruct],
# MAGIC     [$Table].[shipmode] as [shipmode],
# MAGIC     [$Table].[comment] as [comment]
# MAGIC from [lh_tpch19_100].[dbo].[lineitem] as [$Table]

# METADATA ********************

# META {
# META   "language": "sparksql",
# META   "language_group": "synapse_pyspark"
# META }

# CELL ********************

# MAGIC %%sql
# MAGIC select
# MAGIC     partkey,
# MAGIC     suppkey,
# MAGIC     linenumber,
# MAGIC     quantity,
# MAGIC     extendedprice,
# MAGIC     discount,
# MAGIC     tax,
# MAGIC     returnflag,
# MAGIC     linestatus,
# MAGIC     shipdate,
# MAGIC     commitdate,
# MAGIC     receiptdate,
# MAGIC     shipinstruct,
# MAGIC     shipmode,
# MAGIC     comment
# MAGIC from lh_tpch19_100.lineitem as l
# MAGIC limit 10;

# METADATA ********************

# META {
# META   "language": "sparksql",
# META   "language_group": "synapse_pyspark"
# META }
