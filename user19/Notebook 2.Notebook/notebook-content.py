# Fabric notebook source

# METADATA ********************

# META {
# META   "kernel_info": {
# META     "name": "synapse_pyspark"
# META   },
# META   "dependencies": {
# META     "lakehouse": {
# META       "default_lakehouse": "ded7bbd0-2c15-4c80-94d9-178f9f31e524",
# META       "default_lakehouse_name": "lh_tpch19_100",
# META       "default_lakehouse_workspace_id": "3c6cce90-d67d-4708-9c1f-574ad7d54f9f",
# META       "known_lakehouses": [
# META         {
# META           "id": "ded7bbd0-2c15-4c80-94d9-178f9f31e524"
# META         }
# META       ]
# META     }
# META   }
# META }

# CELL ********************

# Welcome to your new notebook
# Type here in the cell editor to add code!

customer = spark.sql("SELECT * FROM lh_tpch19_100.customer LIMIT 1000")
display(customer)

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# CELL ********************

lineitem = spark.sql("SELECT * FROM lh_tpch19_100.lineitem LIMIT 1000")
display(lineitem)

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# CELL ********************


# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# CELL ********************

# Code generated by Data Wrangler for PySpark DataFrame

from datetime import datetime
from pyspark.ml.feature import StringIndexer, OneHotEncoder
from pyspark.ml.functions import vector_to_array
from pyspark.sql import functions as F
from pyspark.sql import types as T

def clean_data(lineitem):
    # Change column type to datetime64[ns] for columns: 'shipdate', 'commitdate', 'receiptdate'
    lineitem = lineitem.withColumn('shipdate', lineitem['shipdate'].cast(T.TimestampType()))
    lineitem = lineitem.withColumn('commitdate', lineitem['commitdate'].cast(T.TimestampType()))
    lineitem = lineitem.withColumn('receiptdate', lineitem['receiptdate'].cast(T.TimestampType()))
    # One-hot encode column: 'returnflag'
    # ⚠️ This was generated to match the original pandas logic but may have performance issues.
    def one_hot_encode_col(df, key):
        insert_idx = df.columns.index(key)
        indexer = StringIndexer(inputCol=key, outputCol='%s_numeric' % str(key), handleInvalid='keep')
        indexer_fitted = indexer.fit(df)
        df_indexed = indexer_fitted.transform(df)
        encoder = OneHotEncoder(inputCols=['%s_numeric' % str(key)], outputCols=['%s_onehot' % str(key)], dropLast=False)
        df_onehot = encoder.fit(df_indexed).transform(df_indexed)
        df_col_onehot = df_onehot.select('*', vector_to_array('%s_onehot' % str(key)).alias('%s_col_onehot' % str(key)))
        labels = sorted(indexer_fitted.labels) + ['%s_nan' % str(key)]
        cols_expanded = [(F.col('%s_col_onehot' % str(key))[i].alias('%s_%s' % (str(key), labels[i]))) for i in range(len(labels))]
        df = df_col_onehot.select(*df.columns[:insert_idx], *cols_expanded, *df.columns[insert_idx+1:])
        return df
    lineitem = one_hot_encode_col(lineitem, 'returnflag')
    # Filter rows based on column: 'shipdate'
    lineitem = lineitem.filter(lineitem['shipdate'] > today)
    return lineitem

lineitem_clean = clean_data(lineitem)
display(lineitem_clean)

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# CELL ********************

datetime.today.strftime('%Y-%m-%d-%H:%M:%S')

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# CELL ********************

from datetime import datetime
today = datetime.today().strftime('%Y-%m-%d')

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# CELL ********************

df = spark.sql("SELECT * FROM lh_tpch19_100.customer LIMIT 1000")
display(df)

df = spark.sql("SELECT * FROM lh_tpch19_100.lineitem LIMIT 1000")
display(df)

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# CELL ********************

# Code generated by Data Wrangler for PySpark DataFrame

def clean_data(lineitem):
    # Filter rows based on column: 'linenumber'
    lineitem = lineitem.filter(lineitem['linenumber'] > 0)
    return lineitem

lineitem_clean = clean_data(lineitem)
display(lineitem_clean)

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }
